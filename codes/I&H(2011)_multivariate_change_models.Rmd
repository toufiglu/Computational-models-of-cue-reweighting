---
title: "The ideal adaptor and the normalization change models"
output: html_document
date: "2023-12-30"
---
```{r setup, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
source("libraries.R")
source("functions.R")
source("parameters.R")
source("new_functions.R")
# set.seed(83984)
```

# Pretraining and normalization of all tokens used
```{r filter pretraining data from C&W and get ideal observer}

# training_trials and test_trials contain all the tokens that will be talker-normalized; each token appears only once

## Yiming: let's revisit the procedure of talker-normalization for the experimental talker, in terms of how repetitions of the same token should be used in this process (cf. Zhang et al. 2018)

# Yiming's response: my approach is to leave the model with a record for the stimuli, so that there will be a normalised value for the stimuli. Perhaps we should develop a more dynamic approach, where, after each block, we do the normalization again?  

training_trials <- expand.grid(
    VOT = c(-20, -10, 0, 20, 30, 40),
    f0 = seq(220, 300, by=10),
    Talker = "experiment"
    ) %>% 
  mutate(category = case_when(
      VOT %in% c(-20, -10, 0) ~ "b",
      TRUE ~ "p"))

test_trials <- data.frame(
  VOT = 10,
  f0 = c(230, 230, 290, 290),
  Talker = 'experiment',
  category = c('b', 'p', 'b', 'p')
) 

experiment_pretraining <- rbind(training_trials, test_trials) %>% 
  mutate(f0_Mel = phonR::normMel(f0))

Long_term_knowledge <- readRDS("d.chodroff_wilson.rds") %>%
  filter(poa == "/b/-/p/") %>%
  droplevels() %>% 
  filter(
    between(VOT, mean(VOT) - 3 * sd(VOT), mean(VOT) + 3 * sd(VOT)),
    between(f0_Mel, mean(f0_Mel) - 3 * sd(f0_Mel), mean(f0_Mel) + 3 * sd(f0_Mel))) %>% 
  group_by(Talker, category) %>% 
  mutate(n = n()) %>%
  group_by(Talker) %>%
  mutate(
    n_min = min(n),
    n_category = n_distinct(category)) %>%
  # select talkers with both categories
  filter(n_category == 2) %>%
  group_by(Talker, category) %>%
  sample_n(size = first(n_min)) %>%
  ungroup() %>%
  select(Talker, VOT, f0, f0_Mel, category) %>% 
  bind_rows(experiment_pretraining) %>% 
  mutate(
    f0_centered = round(apply_ccure(f0_Mel, data = .), 0),
    VOT_centered = round(apply_ccure(VOT, data = .), 0)
  )

experiment_pretraining <- Long_term_knowledge %>% 
  filter(Talker == 'experiment')

# reference table for normalization to be used later.
f0_reference <- experiment_pretraining %>% 
  select(f0, f0_Mel, f0_centered) %>% 
  distinct()

VOT_reference <- experiment_pretraining %>% 
  select(VOT, VOT_centered) %>% 
  distinct()

Long_term_knowledge <- Long_term_knowledge %>% 
  filter(Talker != 'experiment')

# Yiming: modify the code so that the long-term knowledge part stands on its own. That is, no matter what training trials and test trials are used for specific experimental data, the long-term knowledge talker-normalization is done in the same way and we hold it constant.
```

# Create ideal adaptor
```{r create ideal adaptor}
prior_marginal_VOT_f0_stats <-
  Long_term_knowledge %>%
  group_by(Talker) %>%
  summarise(across(c(VOT, f0_Mel), mean)) %>% 
  ungroup() %>%
  summarise(
    x_mean = list(c(VOT = mean(VOT), f0 = mean(f0_Mel))),
    x_var_VOT = var(VOT),
    x_var_f0 = var(f0_Mel),
    x_cov = list(cov(cbind(VOT, f0_Mel))))

m.VOT_f0_MVG <-
  make_MVG_from_data(
  data = Long_term_knowledge,
  category = "category",
  cues = cues)

m.io.VOT_f0.IH <- #make ideal observer for the I&H(2011) experiment, a bivariate Gaussian distribution.
  m.VOT_f0_MVG  %>%
  make_stop_VOTf0_ideal_observer() %>% 
  arrange(category)

m.ia.VOT_f0.IH <-
  crossing(
    prior_kappa = prior_kappa.plot,
    prior_nu = prior_nu.plot) %>% 
  rowwise() %>%
  mutate(ideal_adaptor = map2(prior_kappa, prior_nu, ~ make_stop_VOTf0_ideal_adaptor(m = m.io.VOT_f0.IH, kappa = .x, nu = .y))) %>% 
  unnest(ideal_adaptor) %>% 
  arrange(category)
```

#Exposure data
```{r format the exposure data}
canonical <- tribble(
  ~VOT, ~f0,
  -20, 230,
  -10, 220,
  -10, 230,
  -10, 240,
  0, 230,
  20, 290,
  30, 280,
  30, 290,
  30, 300,
  40, 290
)

neutral = tribble(
  ~VOT, ~f0,
  -20, 260,
  -10, 250,
  -10, 260,
  -10, 270,
    0, 260,
    20, 260,
    30, 250,
    30, 260,
    30, 270,
    40, 260
   )

reversed = tribble(
  ~VOT, ~f0,
  -20, 290,
  -10, 280,
  -10, 290,
  -10, 300,
    0, 290,
    20, 230,
    30, 220,
    30, 230,
    30, 240,
    40, 230
   )

d.IH.canonical <- get_exposure_data(canonical, Condition='canonical')
d.IH.neutral <- get_exposure_data(neutral, Condition='neutral')
d.IH.reversed <- get_exposure_data(reversed, Condition='reversed')
```

#Test data
```{r format the test tokens}
d.IH.test <- tibble(
  VOT = 10,
  f0 = c(230,290) 
) %>% 
  left_join(f0_reference, by='f0') %>%
  left_join(VOT_reference, by='VOT') %>% 
  select(f0_centered, VOT_centered) %>% 
  rename(f0_Mel=f0_centered, VOT=VOT_centered) %>% 
  mutate(Phase='test',
         Item.Category=NA,
         Item.Intended_category = case_when(
           f0_Mel==199 ~ '/b/',
           TRUE ~ '/p/'),
         x=map2(VOT, f0_Mel, ~ c("VOT" = .x, "f0_Mel" = .y)),
         Item.Type='test',
         Block=1) %>% 
  crossing(Condition='test') %>% 
  mutate(Subject=paste(Condition, n.subject, sep = ".")) %>% 
  mutate(ItemID=as.character(row_number()))
```

## Representation models
```{r ideal adaptor model and results for different blocks}
update_representations_and_categorize_test <- function(
  prior,
  exposure,
  test,
  cues = c("VOT", "f0_Mel")
) {
  update_NIW_ideal_adaptor_incrementally(
    prior = prior,
    exposure = exposure,
    exposure.category = "Item.Category",
    exposure.cues = cues,
    noise_treatment = "marginalize",
    lapse_treatment = "marginalize",
    method = "label-certain",
    keep.update_history = FALSE,
    keep.exposure_data = FALSE) %>%
    nest(posterior = everything()) %>%
    add_test_and_categorize(test)
}

get_representation_models_for_plot <- function(
    prior_kappa = prior_kappa.plot,
    prior_nu = prior_nu.plot,
    d.IH.exposure,
    ideal_adaptor,
    type
){
  all_representations <- list()
  Condition = d.IH.exposure$Condition[[1]]
    if (RESET_MODELS || !file.exists(get_path(paste0("../models/d.IH.results.representations_", example_label, "_", Condition, "_", type, ".rds")))){
    
    for(i in 1:10){  
        set.seed(i)
      # In IH11, exposure trials were presented in random order for each iteration of the 10 iterations. test trials are interspersed with exposure trials. We are unable to implement the interleaving exposure and test trials, but exposure trials are reshuffled in every run. After each iteration, the test trial results are obtained, and the /p/ responses for the two test trials are averaged over the 10 iterations.
        d.IH.exposure<-d.IH.exposure[sample(nrow(d.IH.exposure)),]
        
        if(i == 1){
          # Use the ideal adaptor for the first iteration
          m.ia.VOT_f0.IH.plot_sample <- ideal_adaptor
         
        } else {
          # Use the posterior from the previous iteration for the subsequent iteration
          m.ia.VOT_f0.IH.plot_sample <- all_representations[[i-1]] %>% 
          mutate_at(vars(starts_with("prior_")), ~as.numeric(as.character(.x))) %>%
          # at this point, there are always two bivariate Gaussian distributions for /b/ and /p/, respectively. Each of them will assign a posterior probability for the two test tokens, one is intended to be /b/ and another /p/. We end up having four rows for each kappa and nu combination. However, what we really need is just the two posterior Gaussian distributions. Therefore, the filter is used here. 
          filter(Item.Intended_category == "/p/") %>% 
          select(prior_kappa, prior_nu, posterior) %>% 
          unnest(posterior)
        }
        
      representations.pred <- 
        d.IH.exposure %>%
        nest(data = -c(Condition, Subject)) %>%
        crossing(
          m.ia.VOT_f0.IH.plot_sample %>%
            nest(prior = -c(prior_kappa, prior_nu))) %>%
        group_by(Condition, Subject, prior_kappa, prior_nu) %>%
        group_modify(~ update_representations_and_categorize_test(prior = .x$prior[[1]], exposure = .x$data[[1]], test = d.IH.test)) %>%
        mutate_at(vars(starts_with("prior_")), ~factor(.x)) %>%
        mutate_at(vars(starts_with("prior_")), fct_rev) %>%
        ungroup() %>% 
        mutate(Iteration = i)
        
        # Ensure to add the result to the all_representations list
        all_representations[[i]] <- representations.pred
         saveRDS(all_representations, get_path(paste0("../models/d.IH.results.representations_", example_label, "_", Condition, "_", type, ".rds")))
      }
    }
    
    else {
      all_representations <- readRDS(get_path(paste0("../models/d.IH.results.representations_", example_label, "_", Condition, "_", type, ".rds")))
    }
  
  
  return(all_representations)
}



#canonical
representation_IH_canonical_independent <- 
  get_representation_models_for_plot(d.IH.exposure = d.IH.canonical, ideal_adaptor=m.ia.VOT_f0.IH, type="independent") %>%
  lapply(function(x) {
    mutate(x, Condition = "canonical_independent")
  })

# as the canonical block is the first block, its independent and sequential results are the same.
representation_IH_canonical_sequential <- representation_IH_canonical_independent %>% 
  lapply(function(x) {
    mutate(x, Condition = "canonical_sequential")
  })

#neutral
representation_IH_neutral_independent <- 
  get_representation_models_for_plot(d.IH.exposure = d.IH.neutral, ideal_adaptor=m.ia.VOT_f0.IH, type="independent") %>% 
  lapply(function(x) {
    mutate(x, Condition = "neutral_independent")
  })

representation_IH_neutral_sequential <- get_representation_models_for_plot(d.IH.exposure = d.IH.neutral,  ideal_adaptor=model_for_sequential(representation_IH_canonical_independent[[10]]), type="sequential") %>% 
  lapply(function(x) {
    mutate(x, Condition = "neutral_sequential")
  })

# Yiming: set a parameter to specify the input to the 'model_for_sequential' function

#reversed
representation_IH_reversed_independent <- get_representation_models_for_plot(d.IH.exposure = d.IH.reversed, ideal_adaptor=m.ia.VOT_f0.IH, type="independent") %>% 
  lapply(function(x) {
    mutate(x, Condition = "reversed_independent")
  })

representation_IH_reversed_sequential <- get_representation_models_for_plot(d.IH.exposure = d.IH.reversed, ideal_adaptor=model_for_sequential(representation_IH_neutral_sequential[[10]]), type="sequential") %>% 
  lapply(function(x) {
    mutate(x, Condition = "reversed_sequential")
  })

vars <- ls()
rep_models <- grep("^representation_IH_(canonical|neutral|reversed)", vars, value = TRUE)
r_rep <- map(rep_models, rep_processing) %>% bind_rows() %>% 
  separate(Condition,into = c("block", "type"), sep = "_", remove = FALSE)
```

#Figure4: in this version I plotted independent and sequential separately
```{r Figure4: ideal adaptor results}
make_results_plot_representations <- function(data) {
  # for clarity we only present results for a small range of values.
  # Specifically, changing prior confidence in covariance does not effect results too much.
  # We used nu=256, which means that listeners still largely rely on their prior experiences (it will take more than 256 input tokens to completely update previous experiences.)
  # The three kappa values selected are representative of the general patterns we observe in the data.
  # But readers are encouraged to delete this line and print the full range of results.

  p.results <-
    basic_IH_result_plot(data) +
    facet_grid(
      prior_kappa ~ prior_nu,
      labeller = label_bquote(
        rows = {kappa[.(categories.IH[1])] == kappa[.(categories.IH[2])]} == .(as.character(prior_kappa)))) +
    ggh4x::force_panelsizes(cols = result.panel.size, rows = result.panel.size)

}

figure_independent <- make_results_plot_representations(r_rep %>% filter(type=="independent"))


figure_sequential <- make_results_plot_representations(r_rep %>% filter(type=="sequential"))

figure_independent
figure_sequential
```

# get trajectory results
```{r gather results across different blocks}
independent_results <- get_trajectory_results(representation_IH_canonical_independent, representation_IH_neutral_independent, representation_IH_reversed_independent)

sequential_results <- get_trajectory_results(representation_IH_canonical_sequential, representation_IH_neutral_sequential, representation_IH_reversed_sequential)
```

# trajectory visualization
```{r visualiaztion of trajectory in the ideal adaptor models}
IH11_trajectory_independent <- plot_response_trajectory(independent_results)
IH11_trajectory_independent

IH11_trajectory_sequential <- plot_response_trajectory(sequential_results)
IH11_trajectory_sequential
```

## Normalization models
```{r the normalization change model, as well as its results for different blocks}
m.ia.VOT_f0.IH.normalization <- m.ia.VOT_f0.IH %>% 
  filter(prior_kappa == max(prior_kappa) & prior_nu == max(prior_nu)) %>%
  nest(posterior = everything()) %>% 
  crossing(prior_kappa.normalization = c(4, 16, 64, 256, 1024)) %>% 
  mutate(Item.Intended_category="/p/",
         prior_kappa.normalization = factor(prior_kappa.normalization))
  

# canonical
normalization_IH_canonical_independent <- get_normalization_models_for_plot(d.IH.exposure=d.IH.canonical, normalization.prior=m.ia.VOT_f0.IH.normalization, type="independent") %>% 
  lapply(function(x) {
    mutate(x, Condition = "canonical_independent")
  })

normalization_IH_canonical_sequential <- normalization_IH_canonical_independent %>% 
  lapply(function(x) {
    mutate(x, Condition = "canonical_sequential")
  })

# neutral
normalization_IH_neutral_independent <- get_normalization_models_for_plot(d.IH.exposure=d.IH.neutral, normalization.prior=m.ia.VOT_f0.IH.normalization, type="independent") %>%  
  lapply(function(x) {
    mutate(x, Condition = "neutral_independent")
  })

normalization_IH_neutral_sequential <- get_normalization_models_for_plot(d.IH.exposure=d.IH.neutral, normalization.prior=normalization_IH_canonical_independent[[10]], type="sequential") %>% 
  lapply(function(x) {
    mutate(x, Condition = "neutral_sequential")
  })

# reversed
normalization_IH_reversed_independent <- get_normalization_models_for_plot(d.IH.exposure=d.IH.reversed, normalization.prior=m.ia.VOT_f0.IH.normalization, type="independent") %>% 
  lapply(function(x) {
    mutate(x, Condition = "reversed_independent")
  })

normalization_IH_reversed_sequential <- get_normalization_models_for_plot(d.IH.exposure=d.IH.reversed, normalization.prior=normalization_IH_neutral_sequential[[10]], type="sequential") %>% 
  lapply(function(x) {
    mutate(x, Condition = "reversed_sequential")
  })

vars <- ls()
norm_models <- grep("^normalization_IH_(canonical|neutral|reversed)", vars, value = TRUE)

r_norm <- map(norm_models, norm_processing) %>% bind_rows() %>% 
  separate(Condition,into = c("block", "type"), sep = "_", remove = FALSE)
```

#Figure5
```{r Figure 5: normalization change model results}
make_results_plot_normalization <- function(data){
  data <- data %>%  # we only show the results for this range, because the patterns are roughly similar.
    filter(prior_kappa.normalization %in% c(16,64,256))
  
  p.results <- 
    basic_IH_result_plot(data) +
    facet_grid(
      prior_kappa.normalization ~ type,
      labeller = label_bquote(
        rows = ~kappa == .(as.character(prior_kappa.normalization)))) +   
    ggh4x::force_panelsizes(cols = result.panel.size, rows = result.panel.size)
  
}

Figure5 <- make_results_plot_normalization(r_norm)
Figure5
```




