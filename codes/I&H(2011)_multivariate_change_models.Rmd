---
title: "The ideal adaptor and the normalization change models"
output: html_document
date: "2023-12-30"
---
```{r setup, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
source("libraries.R")
source("functions.R")
source("parameters.R")
```

# Load functions: functions for packaging, processing, and visualzing data
```{r load functions to be used below}
# format exposure data
get_exposure_data <- function(input_data, Condition, n.subject=1) {
  input_data <- input_data %>%
    left_join(f0_reference, by='f0') %>%
    left_join(VOT_reference, by='VOT') %>% 
    mutate(Condition=Condition,
           Item.Type=Condition,
           Item.Category = case_when(
                VOT %in% c(-20, -10, 0) ~ "/b/",
                TRUE ~ "/p/")) %>%
    dplyr::select(-VOT, -f0, -f0_Mel) %>%
    rename(VOT = VOT_centered,
           f0_Mel = f0_centered) %>% 
    crossing(Subject = factor(1:n.subject)) %>%
    mutate(Subject = paste(Condition, Subject, sep = "."),
           Phase = 'training',
           x = map2(VOT, f0_Mel, ~ c("VOT" = .x, "f0_Mel" = .y))) %>% 
    mutate(ItemID=as.character(row_number()))
  
  names(input_data$x) <- NULL
  
  return(input_data)
}

# a function used to deal with sequential models
model_for_sequential <- function(representation.model) {
  representation.model <- representation.model %>% 
        mutate_at(vars(starts_with("prior_")), ~as.numeric(as.character(.x))) %>%
        filter(Item.Intended_category == "/p/") %>% 
        select(prior_kappa, prior_nu, posterior) %>%
        unnest(posterior)
}

# the following two functions will be used for processing results of the ideal adaptor and the normalization change model.
rep_processing <- function(variable) {
  data <- get(variable, envir = .GlobalEnv)
  results <- 
    data %>%
    bind_rows() %>% 
    mutate(prob.p = ifelse(Item.Intended_category =="/p/", response, 1-response),
           normalised_f0 = ifelse(Item.Intended_category =="/p/", 269, 199),
           normalised_f0 = factor(normalised_f0)) %>% 
    group_by(Condition, prior_kappa, prior_nu, Item.Intended_category, normalised_f0) %>% # normalised_f0 is essentially determined by Item.Intended_category. It is included here to make sure that the column remains, which will be used for plotting below.
    summarise(mean_prob_p = mean(prob.p), .groups = 'drop') %>% 
    rename(prob.p=mean_prob_p)
  
  return(results)
}

norm_processing <- function(variable) {
  data <- get(variable, envir = .GlobalEnv)
  results <- 
    data %>%
    bind_rows() %>% 
    mutate(prob.p = ifelse(Item.Intended_category =="/p/", response, 1-response),
           normalised_f0 = ifelse(Item.Intended_category =="/p/", 269, 199),
           normalised_f0 = factor(normalised_f0)) %>% 
    group_by(Condition, prior_kappa.normalization, Item.Intended_category, normalised_f0) %>% 
    summarise(mean_prob_p = mean(prob.p), .groups = 'drop') %>% 
    rename(prob.p=mean_prob_p)
  
  return(results)
}

# visualization function
basic_IH_result_plot <- function(data) {
  data %>%
    mutate(Levels = ifelse(normalised_f0 == 199, "Low f0", "High f0")) %>% 
    ggplot(aes(x = block, y = prob.p, group = Levels)) +
    list(
      geom_point(size = 2, aes(color = Levels)),
      scale_color_manual(values = c("Low f0" = "orange", "High f0" = "blue")),
      coord_cartesian(ylim = c(0, 1.1)),
      scale_y_continuous(breaks = c(0, 0.5, 1)),
      scale_x_discrete(labels= c("canonical", "neutral", "reversed")),
      xlab("Exposure condition"),
      ylab("Proportion of /p/ responses"),
      theme(
        legend.key.height= duo.panel.key,
        legend.position = "top", 
        axis.text.x = element_text(angle=22.5, hjust=1, size = 20),
        axis.text.y = element_text(size = 20),
        axis.title.x = element_text(size = 20, face = "bold"),
        axis.title.y = element_text(size = 20, face = "bold"),
        legend.text = element_text (size = 20),
        legend.title = element_text(size = 20, face = "bold"),
        plot.title = element_text(size = 20),
        strip.text.x = element_text(size= 20, face = "bold"),
        strip.text.y = element_text(size= 20, face = "bold"),
        panel.background = element_rect(fill = "white"),
        panel.grid.major = element_line(color = "grey", size = 0.5),
        panel.grid.minor = element_line(color = "lightgrey", size = 0.25))
      )
}
```

# Pretraining and normalization of all tokens used
```{r filter pretraining data from C&W and get ideal observer}
training_trials <- expand.grid(
    VOT = c(-20, -10, 0, 20, 30, 40),
    f0 = seq(220, 300, by=10),
    Talker = "experiment"
    ) %>% 
  mutate(category = case_when(
      VOT %in% c(-20, -10, 0) ~ "b",
      TRUE ~ "p"))

test_trials <- data.frame(
  VOT = 10,
  f0 = c(230, 230, 290, 290),
  Talker = 'experiment',
  category = c('b', 'p', 'b', 'p')
) 

experiment_pretraining <- rbind(training_trials, test_trials) %>% 
  mutate(f0_Mel = phonR::normMel(f0))

Long_term_knowledge <- readRDS("d.chodroff_wilson.rds") %>%
  filter(poa == "/b/-/p/") %>%
  droplevels() %>% 
  filter(
    between(VOT, mean(VOT) - 3 * sd(VOT), mean(VOT) + 3 * sd(VOT)),
    between(f0_Mel, mean(f0_Mel) - 3 * sd(f0_Mel), mean(f0_Mel) + 3 * sd(f0_Mel))) %>% 
  group_by(Talker, category) %>% 
  mutate(n = n()) %>%
  group_by(Talker) %>%
  mutate(
    n_min = min(n),
    n_category = n_distinct(category)) %>%
  # select talkers with both categories
  filter(n_category == 2) %>%
  group_by(Talker, category) %>%
  sample_n(size = first(n_min)) %>%
  ungroup() %>%
  select(Talker, VOT, f0, f0_Mel, category) %>% 
  bind_rows(experiment_pretraining) %>% 
  mutate(
    f0_centered = round(apply_ccure(f0_Mel, data = .), 0),
    VOT_centered = round(apply_ccure(VOT, data = .), 0)
  )

experiment_pretraining <- Long_term_knowledge %>% 
  filter(Talker == 'experiment')

# reference table for normalization to be used later.
f0_reference <- experiment_pretraining %>% 
  select(f0, f0_Mel, f0_centered) %>% 
  distinct()

VOT_reference <- experiment_pretraining %>% 
  select(VOT, VOT_centered) %>% 
  distinct()

Long_term_knowledge <- Long_term_knowledge %>% 
  filter(Talker != 'experiment')
```

# Create ideal adaptor
```{r create ideal adaptor}
prior_marginal_VOT_f0_stats <-
  Long_term_knowledge %>%
  group_by(Talker) %>%
  summarise(across(c(VOT, f0_Mel), mean)) %>% 
  ungroup() %>%
  summarise(
    x_mean = list(c(VOT = mean(VOT), f0 = mean(f0_Mel))),
    x_var_VOT = var(VOT),
    x_var_f0 = var(f0_Mel),
    x_cov = list(cov(cbind(VOT, f0_Mel))))

m.VOT_f0_MVG <-
  make_MVG_from_data(
  data = Long_term_knowledge,
  category = "category",
  cues = cues)

m.io.VOT_f0.IH <- #make ideal observer for the I&H(2011) experiment, a bivariate Gaussian distribution.
  m.VOT_f0_MVG  %>%
  make_stop_VOTf0_ideal_observer() %>% 
  arrange(category)

m.ia.VOT_f0.IH <-
  crossing(
    prior_kappa = prior_kappa.plot,
    prior_nu = prior_nu.plot) %>% 
  rowwise() %>%
  mutate(ideal_adaptor = map2(prior_kappa, prior_nu, ~ make_stop_VOTf0_ideal_adaptor(m = m.io.VOT_f0.IH, kappa = .x, nu = .y))) %>% 
  unnest(ideal_adaptor) %>% 
  arrange(category)
```

#Exposure data
```{r format the exposure data}
canonical <- tribble(
  ~VOT, ~f0,
  -20, 230,
  -10, 220,
  -10, 230,
  -10, 240,
  0, 230,
  20, 290,
  30, 280,
  30, 290,
  30, 300,
  40, 290
)

neutral = tribble(
  ~VOT, ~f0,
  -20, 260,
  -10, 250,
  -10, 260,
  -10, 270,
    0, 260,
    20, 260,
    30, 250,
    30, 260,
    30, 270,
    40, 260
   )

reversed = tribble(
  ~VOT, ~f0,
  -20, 290,
  -10, 280,
  -10, 290,
  -10, 300,
    0, 290,
    20, 230,
    30, 220,
    30, 230,
    30, 240,
    40, 230
   )

d.IH.canonical <- get_exposure_data(canonical, Condition='canonical')
d.IH.neutral <- get_exposure_data(neutral, Condition='neutral')
d.IH.reversed <- get_exposure_data(reversed, Condition='reversed')
```

#Test data
```{r format the test tokens}
d.IH.test <- tibble(
  VOT = 10,
  f0 = c(230,290) 
) %>% 
  left_join(f0_reference, by='f0') %>%
  left_join(VOT_reference, by='VOT') %>% 
  select(f0_centered, VOT_centered) %>% 
  rename(f0_Mel=f0_centered, VOT=VOT_centered) %>% 
  mutate(Phase='test',
         Item.Category=NA,
         Item.Intended_category = case_when(
           f0_Mel==199 ~ '/b/',
           TRUE ~ '/p/'),
         x=map2(VOT, f0_Mel, ~ c("VOT" = .x, "f0_Mel" = .y)),
         Item.Type='test',
         Block=1) %>% 
  crossing(Condition='test') %>% 
  mutate(Subject=paste(Condition, n.subject, sep = ".")) %>% 
  mutate(ItemID=as.character(row_number()))
```

## Representation models
```{r ideal adaptor model and results for different blocks}
update_representations_and_categorize_test <- function(
  prior,
  exposure,
  test,
  cues = c("VOT", "f0_Mel")
) {
  update_NIW_ideal_adaptor_incrementally(
    prior = prior,
    exposure = exposure,
    exposure.category = "Item.Category",
    exposure.cues = cues,
    noise_treatment = "marginalize",
    lapse_treatment = "marginalize",
    method = "label-certain",
    keep.update_history = FALSE,
    keep.exposure_data = FALSE) %>%
    nest(posterior = everything()) %>%
    add_test_and_categorize(test)
}

get_representation_models_for_plot <- function(
    prior_kappa = prior_kappa.plot,
    prior_nu = prior_nu.plot,
    d.IH.exposure,
    ideal_adaptor,
    type
){
  all_representations <- list()
  Condition = d.IH.exposure$Condition[[1]]
  if (RESET_MODELS || !file.exists(get_path(paste0("../models/d.IH.results.representations_", example_label, "_", Condition, "_", type, ".rds")))){
  
  for(i in 1:10){  
      set.seed(i)
    # In IH11, exposure trials were presented in random order for each iteration of the 10 iterations. test trials are interspersed with exposure trials. We are unable to implement the interleaving exposure and test trials, but exposure trials are reshuffled in every run. After each iteration, the test trial results are obtained, and the /p/ responses for the two test trials are averaged over the 10 iterations.
      d.IH.exposure<-d.IH.exposure[sample(nrow(d.IH.exposure)),]
      
      if(i == 1){
        # Use the ideal adaptor for the first iteration
        m.ia.VOT_f0.IH.plot_sample <- ideal_adaptor
       
      } else {
        # Use the posterior from the previous iteration for the subsequent iteration
        m.ia.VOT_f0.IH.plot_sample <- all_representations[[i-1]] %>% 
        mutate_at(vars(starts_with("prior_")), ~as.numeric(as.character(.x))) %>%
        # at this point, there are always two bivariate Gaussian distributions for /b/ and /p/, respectively. Each of them will assign a posterior probability for the two test tokens, one is intended to be /b/ and another /p/. We end up having four rows for each kappa and nu combination. However, what we really need is just the two posterior Gaussian distributions. Therefore, the filter is used here. 
        filter(Item.Intended_category == "/p/") %>% 
        select(prior_kappa, prior_nu, posterior) %>% 
        unnest(posterior)
      }
      
    representations.pred <- 
      d.IH.exposure %>%
      nest(data = -c(Condition, Subject)) %>%
      crossing(
        m.ia.VOT_f0.IH.plot_sample %>%
          nest(prior = -c(prior_kappa, prior_nu))) %>%
      group_by(Condition, Subject, prior_kappa, prior_nu) %>%
      group_modify(~ update_representations_and_categorize_test(prior = .x$prior[[1]], exposure = .x$data[[1]], test = d.IH.test)) %>%
      mutate_at(vars(starts_with("prior_")), ~factor(.x)) %>%
      mutate_at(vars(starts_with("prior_")), fct_rev) %>%
      ungroup() %>% 
      mutate(Iteration = i)
      
      # Ensure to add the result to the all_representations list
      all_representations[[i]] <- representations.pred
       saveRDS(all_representations, get_path(paste0("../models/d.IH.results.representations_", example_label, "_", Condition, "_", type, ".rds")))
    }
    }
    else {
      all_representations <- readRDS(get_path(paste0("../models/d.IH.results.representations_", example_label, "_", Condition, "_", type, ".rds")))
    }
  
  
  return(all_representations)
}

#canonical
representation_IH_canonical_independent <- 
  get_representation_models_for_plot(d.IH.exposure = d.IH.canonical, ideal_adaptor=m.ia.VOT_f0.IH, type="independent") %>%
  lapply(function(x) {
    mutate(x, Condition = "canonical_independent")
  })

# as the canonical block is the first block, its independent and sequential results are the same.
representation_IH_canonical_sequential <- representation_IH_canonical_independent %>% 
  lapply(function(x) {
    mutate(x, Condition = "canonical_sequential")
  })

#neutral
representation_IH_neutral_independent <- 
  get_representation_models_for_plot(d.IH.exposure = d.IH.neutral, ideal_adaptor=m.ia.VOT_f0.IH, type="independent") %>% 
  lapply(function(x) {
    mutate(x, Condition = "neutral_independent")
  })

representation_IH_neutral_sequential <- get_representation_models_for_plot(d.IH.exposure = d.IH.neutral, ideal_adaptor=model_for_sequential(representation_IH_canonical_independent[[10]]), type="sequential") %>% 
  lapply(function(x) {
    mutate(x, Condition = "neutral_sequential")
  })

#reversed
representation_IH_reversed_independent <- get_representation_models_for_plot(d.IH.exposure = d.IH.reversed, ideal_adaptor=m.ia.VOT_f0.IH, type="independent") %>% 
  lapply(function(x) {
    mutate(x, Condition = "reversed_independent")
  })

representation_IH_reversed_sequential <- get_representation_models_for_plot(d.IH.exposure = d.IH.reversed, ideal_adaptor=model_for_sequential(representation_IH_neutral_sequential[[10]]), type="sequential") %>% 
  lapply(function(x) {
    mutate(x, Condition = "reversed_sequential")
  })

vars <- ls()
rep_models <- grep("^representation_IH_(canonical|neutral|reversed)", vars, value = TRUE)
r_rep <- map(rep_models, rep_processing) %>% bind_rows() %>% 
  separate(Condition,into = c("block", "type"), sep = "_", remove = FALSE)
```

#Figure4
```{r Figure4: ideal adaptor results}
make_results_plot_representations <- function(data) {
  # for clarity we only present results for a small range of values.
  # Specifically, changing prior confidence in covariance does not effect results too much.
  # We used nu=256, which means that listeners still largely rely on their prior experiences (it will take more than 256 input tokens to completely update previous experiences.)
  # The three kappa values selected are representative of the general patterns we observe in the data.
  # But readers are encouraged to delete this line and print the full range of results.
  data <- data %>% filter(prior_kappa %in% c(16,64,256) & prior_nu == 256)
  
  p.results <-
    basic_IH_result_plot(data) +
    facet_grid(
      prior_kappa ~ type,
      labeller = label_bquote(
        rows = {kappa[.(categories.IH[1])] == kappa[.(categories.IH[2])]} == .(as.character(prior_kappa)))) +
    ggh4x::force_panelsizes(cols = result.panel.size, rows = result.panel.size)

}

Figure4 <- make_results_plot_representations(r_rep)
Figure4
```



## Normalization models
```{r the normalization change model, as well as its results for different blocks}
update_normalization_and_categorize_test <- function(
  prior,
  mu_0 = first(prior_marginal_VOT_f0_stats$x_mean),
  kappa.normalization,
  exposure,
  test
) {

  # Get normalization parameters for exposure data
  exposure.normalization <- 
    exposure %>%
    summarise(
      x_N = length(x),
      x_mean = list(colMeans(reduce(x, rbind))),
      x_cov = list(cov(reduce(x, rbind))))
  
  # Apply normalization based on exposure to test
  mu_inferred <- 1 / 
            (kappa.normalization + exposure.normalization$x_N[[1]]) * 
            (kappa.normalization * mu_0 + exposure.normalization$x_N[[1]] * exposure.normalization$x_mean[[1]])
  
  test %<>%
    mutate(
      x_unnormalized = x,
      x = map(x, ~ .x - (mu_inferred - mu_0)))
      
  test %>%
    select(x_unnormalized, x, Item.Intended_category) %>%
    nest(x = x, Item.Intended_category = c(x, Item.Intended_category, x_unnormalized)) %>%
    mutate(posterior = list(prior)) %>%
    
    # Don't add test again since it's already in the data
    add_test_and_categorize(test = NULL)
}


get_normalization_models_for_plot <- function(
    prior_kappa.normalization = c(4, 16, 64, 256, 1024),
    d.IH.exposure,
    normalization.prior,
    type
){
  all_normalizations <- list()  # Create an empty list to store results from each iteration
  Condition = d.IH.exposure$Condition[[1]]
  
  if (RESET_MODELS || !file.exists(get_path(paste0("../models/d.IH.results.normalization_", example_label, "_", Condition, "_", type, ".rds")))){
    
  for(i in 1:10){  # Loop to iterate 10 times
    set.seed(100+i)
    d.IH.exposure<-d.IH.exposure[sample(nrow(d.IH.exposure)),]

      if(i == 1){
        normalization.adaptor <-  normalization.prior
      } else {
        normalization.adaptor <- all_normalizations[[i-1]]
      }
  
      
      normalization.adaptor <- normalization.adaptor %>% 
        filter(Item.Intended_category == "/p/") %>% 
        select(prior_kappa.normalization, posterior) %>% 
        rename(prior=posterior)
    
      normalization.pred <- 
        d.IH.exposure %>%
        nest(data = -c(Condition, Subject)) %>%
        crossing(prior_kappa.normalization = normalization.adaptor$prior_kappa.normalization,
                 prior = normalization.adaptor$prior) %>%
        mutate(prior_kappa.normalization = as.numeric(as.character(prior_kappa.normalization))) %>% 
        group_by(Condition, Subject, prior_kappa.normalization) %>% 
        group_modify(
          ~ update_normalization_and_categorize_test(
            prior = .x$prior[[1]],
            kappa.normalization = .y$prior_kappa.normalization,
            exposure = .x$data[[1]],
            test = d.IH.test)) %>%
        mutate_at(vars(starts_with("prior_")), ~factor(.x)) %>%
        mutate_at(vars(starts_with("prior_")), fct_rev) %>%
        ungroup()

      all_normalizations[[i]] <- normalization.pred
      }
      saveRDS(all_normalizations, get_path(paste0("../models/d.IH.results.normalization_", example_label, "_", Condition, "_", type, ".rds")))
    } else {
      all_normalizations <- readRDS(get_path(paste0("../models/d.IH.results.normalization_", example_label, "_", Condition, "_", type, ".rds")))
      
    }
  

  return(all_normalizations)
}

m.ia.VOT_f0.IH.normalization <- m.ia.VOT_f0.IH %>% 
  filter(prior_kappa == max(prior_kappa) & prior_nu == max(prior_nu)) %>%
  nest(posterior = everything()) %>% 
  crossing(prior_kappa.normalization = c(4, 16, 64, 256, 1024)) %>% 
  mutate(Item.Intended_category="/p/",
         prior_kappa.normalization = factor(prior_kappa.normalization))
  

# canonical
normalization_IH_canonical_independent <- get_normalization_models_for_plot(d.IH.exposure=d.IH.canonical, normalization.prior=m.ia.VOT_f0.IH.normalization, type="independent") %>% 
  lapply(function(x) {
    mutate(x, Condition = "canonical_independent")
  })

normalization_IH_canonical_sequential <- d.IH.normalization.canonical.independent %>% 
  lapply(function(x) {
    mutate(x, Condition = "canonical_sequential")
  })

# neutral
normalization_IH_neutral_independent <- get_normalization_models_for_plot(d.IH.exposure=d.IH.neutral, normalization.prior=m.ia.VOT_f0.IH.normalization, type="independent") %>%  
  lapply(function(x) {
    mutate(x, Condition = "neutral_independent")
  })

normalization_IH_neutral_sequential <- get_normalization_models_for_plot(d.IH.exposure=d.IH.neutral, normalization.prior=normalization_IH_canonical_independent[[10]], type="sequential") %>% 
  lapply(function(x) {
    mutate(x, Condition = "neutral_sequential")
  })

# reversed
normalization_IH_reversed_independent <- get_normalization_models_for_plot(d.IH.exposure=d.IH.reversed, normalization.prior=m.ia.VOT_f0.IH.normalization, type="independent") %>% 
  lapply(function(x) {
    mutate(x, Condition = "reversed_independent")
  })

normalization_IH_reversed_sequential <- get_normalization_models_for_plot(d.IH.exposure=d.IH.reversed, normalization.prior=normalization_IH_neutral_sequential[[10]], type="sequential") %>% 
  lapply(function(x) {
    mutate(x, Condition = "reversed_sequential")
  })

vars <- ls()
norm_models <- grep("^normalization_IH_(canonical|neutral|reversed)", vars, value = TRUE)

r_norm <- map(norm_models, norm_processing) %>% bind_rows() %>% 
  separate(Condition,into = c("block", "type"), sep = "_", remove = FALSE)
```

#Figure5
```{r Figure 5: normalization change model results}
make_results_plot_normalization <- function(data){
  data <- data %>%  # we only show the results for this range, because the patterns are roughly similar.
    filter(prior_kappa.normalization %in% c(16,64,256))
  
  p.results <- 
    basic_IH_result_plot(data) +
    facet_grid(
      prior_kappa.normalization ~ type,
      labeller = label_bquote(
        rows = ~kappa == .(as.character(prior_kappa.normalization)))) +   
    ggh4x::force_panelsizes(cols = result.panel.size, rows = result.panel.size)
  
}

Figure5 <- make_results_plot_normalization(r_norm)
Figure5
```

