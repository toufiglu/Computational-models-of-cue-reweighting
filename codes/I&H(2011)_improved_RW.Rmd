---
title: "I&H(2011)_improved_RW"
output: html_document
date: "2023-12-08"
---

```{r setup, include=FALSE}
rm(list = ls())
library(ndl)
library(tidyverse)
library("boot")
library(mgcv)
source("functions.R")
maxRep = 1000
```

# Load Rescorla function
```{r RW-code} 
Rescorla = function (cuesOutcomes = train,
                     Lambda=1,
                     rate,
			               w,
			               lg="l") 
{
    cues = unique(unlist(strsplit(cuesOutcomes$Cues, "_")))
    outcomes = unique(unlist(strsplit(cuesOutcomes$Outcomes, "_")))

    preTrained=FALSE
    if (is.na(w)==FALSE){preTrained=TRUE}
    if (preTrained==TRUE) {outcomes = colnames(w)}
    if (preTrained==FALSE) 
     { 
      w = matrix(0, length(cues), length(outcomes)) 
      rownames(w)=cues
      colnames(w)=outcomes
	}
    theCues = strsplit(cuesOutcomes$Cues, "_")
    theOutcomes = strsplit(cuesOutcomes$Outcomes, "_")
    
    if (preTrained==FALSE) {knownOutcomes = NULL}
    if (preTrained==TRUE) {knownOutcomes = outcomes}
    
    for (i in 1:nrow(cuesOutcomes)) {
      cs = theCues[[i]]
      ou = theOutcomes[[i]] 
      toAdd = ou[!is.element(ou, knownOutcomes)]
      knownOutcomes = c(knownOutcomes, toAdd)
      Vtotal = colSums(w[cs,ou,drop=FALSE])
	    w[cs,ou] = t(t(w[cs,ou]) + (Lambda-Vtotal)*rate)
	    otherou = knownOutcomes[!is.element(knownOutcomes, ou)]

      if (!is.null(otherou)) {
         Vtotal = colSums(w[cs,otherou,drop=FALSE])
  	     w[cs,otherou] = t(t(w[cs,otherou]) + (0-Vtotal)*rate)
      }
    }
    return(w)
}
```

# pretrain data
```{r message=FALSE, warning=FALSE}
# the test data are created here to
training_trials <- expand.grid(
    VOT = c(-20, -10, 0, 20, 30, 40),
    f0 = seq(220, 300, by=10),
    Talker = "experiment"
    ) %>% 
  mutate(category = case_when(
      VOT %in% c(-20, -10, 0) ~ "b",
      TRUE ~ "p"))

test_trials <- data.frame(
  VOT = 10,
  f0 = c(230, 230, 290, 290),
  Talker = 'experiment',
  category = c('b', 'p', 'b', 'p')
) # is this the right way to approach it?

experiment_pretraining <- rbind(training_trials, test_trials) %>% 
  mutate(f0_Mel = phonR::normMel(f0))

Long.term.knowledge <- readRDS("d.chodroff_wilson.rds") %>%
  filter(poa == "/b/-/p/") %>%
  droplevels() %>% 
  filter(
    between(VOT, mean(VOT) - 3 * sd(VOT), mean(VOT) + 3 * sd(VOT)),
    between(f0_Mel, mean(f0_Mel) - 3 * sd(f0_Mel), mean(f0_Mel) + 3 * sd(f0_Mel))) %>% 
  group_by(Talker, category) %>% 
  mutate(n = n()) %>%
  group_by(Talker) %>%
  mutate(
    n_min = min(n),
    n_category = n_distinct(category)) %>%
  # select talkers with both categories
  filter(n_category == 2) %>%
  group_by(Talker, category) %>%
  sample_n(size = first(n_min)) %>%
  ungroup() %>%
  select(Talker, VOT, f0, f0_Mel, category) %>% 
  bind_rows(experiment_pretraining) %>% 
  mutate(
    F0_centered = round(apply_ccure(f0_Mel, data = .), 0),
    VOT_centered = round(apply_ccure(VOT, data = .), 0)
  )

experiment_pretraining <- Long.term.knowledge %>% 
  filter(Talker == 'experiment')

F0_reference <- experiment_pretraining %>% 
  select(f0, f0_Mel, F0_centered) %>% 
  distinct()
saveRDS(F0_reference, "F0_reference.rds")

VOT_reference <- experiment_pretraining %>% 
  select(VOT, VOT_centered) %>% 
  distinct()
saveRDS(VOT_reference, "VOT_reference.rds")

experiment_pretraining <- experiment_pretraining %>% 
  mutate (
    Frequency = 0,
    Cues = paste(paste0("normalised.vot", experiment_pretraining$VOT_centered), 
                 paste0("normalised.f0", experiment_pretraining$F0_centered),
                 sep = "_"),
    Outcomes = category
  ) %>% 
  select(Cues, Outcomes, Frequency)
  

bilabials_filtered <- Long.term.knowledge %>% 
  filter(Talker != 'experiment') %>% 
  mutate(category = as.character(category),
         Outcomes = 0)


for (i in 1:dim(bilabials_filtered)[1]) {
  bilabials_filtered$Outcomes[i] = strsplit(bilabials_filtered$category[i], "/")[[1]][2]
}

bilabials_filtered <- bilabials_filtered %>% 
  mutate(
    Cues = paste(paste0("normalised.vot", round(bilabials_filtered$VOT_centered, 0)), 
                 paste0("normalised.f0", round(bilabials_filtered$F0_centered, 0)),
                 sep = "_")
    )

bilabials_pretraining <- bilabials_filtered %>% 
  count(Cues, Outcomes) %>% 
  mutate(Frequency = n) %>% 
  select(-n)

pretraining <- rbind(bilabials_pretraining, experiment_pretraining)
w.pre<-estimateWeights(pretraining)
w.pre
```


# Sanity check: without any training, how does the model categorize?
```{r do not use the canonical trial data, calculate values directly}
low.F0 <- c("normalised.vot22","normalised.f0199")
high.F0 <- c("normalised.vot22","normalised.f0269")
low.F0_values <- w.pre[low.F0, ]
high.F0_values <- w.pre[high.F0, ]
low.F0_sum <- colSums(low.F0_values)
high.F0_sum <- colSums(high.F0_values)


pretraining.results <- data.frame(low.F0 = low.F0_sum, high.F0 = high.F0_sum) 
pretraining.results <- as.data.frame(t(pretraining.results)) %>%
  rownames_to_column(var = "F0") %>%
  mutate(
    Condition = "pretraining",
    F0 = ifelse(F0 == "low.F0", "normalised.199", "normalised.269")
  )


graph.pretraining <- pretraining.results %>% 
  ggplot(aes(x = Condition, y = p, group = F0)) + 
  geom_point(aes(shape = F0), size = 3) +
  theme(legend.text = element_text (size = 12),
        legend.title = element_text(size = 12, face = "bold"),
        plot.title = element_text(size = 12),
        axis.text.y = element_text(size = 10),
        axis.text.x = element_text(size = 12),
        axis.title = element_text(size = 12, face = "bold"))+
  xlab ("Condition") + ylab("Probability of /p/ responses") +
  coord_cartesian(ylim = c(0,1))

graph.pretraining
```

# test items
```{r}
# The raw values for test items are VOT10, F0230,290. Here, we make reference to
# VOT_reference and F0_reference tables.

testStim<-rbind(c("normalised.vot22","normalised.f0199"),
                c("normalised.vot22","normalised.f0269"))
numTestStim<-dim(testStim)[1]
plot.data<-data.frame(testStim,stringsAsFactors=F)
names(plot.data)=c("VOT", "F0")
act.p<-mat.or.vec(numTestStim,maxRep)
act.b<-mat.or.vec(numTestStim,maxRep)
```

# Canonical condition
```{r message=FALSE, warning=FALSE, paged.print=FALSE}
canonical <- tribble(
  ~VOT, ~f0,
  -20, 230,
  -10, 220,
  -10, 230,
  -10, 240,
  0, 230,
  20, 290,
  30, 280,
  30, 290,
  30, 300,
  40, 290
)

canonical %<>% left_join(F0_reference, by='f0') %>% 
  left_join(VOT_reference, by='VOT')

canonical %<>% mutate(
    Frequency = 10,
    Outcomes = case_when(
      VOT %in% c(-20, -10, 0) ~ "b",
      TRUE ~ "p"
    ),
    Cues = paste(paste0("normalised.vot", VOT_centered), 
                 paste0("normalised.f0", F0_centered), sep = "_"),
  ) %>% 
  select(Cues, Outcomes, Frequency)

canonical <- canonical %>%
  slice(rep(1:n(), each = Frequency)) %>% 
  select(-Frequency)

train = canonical
train$Cues<-as.character(train$Cues)
train$Outcomes<-as.character(train$Outcomes)
f0230.canonical<-mat.or.vec(maxRep,2)
f0290.canonical<-mat.or.vec(maxRep,2)

for (nRep in 1:maxRep)
{
    train<-train[sample(nrow(train)),]
    if (nRep==1) {w<-Rescorla(train,rate=0.1,w=w.pre)}
    else {w<-(w*(nRep-1)+Rescorla(train,rate=0.1,w=w.pre))/nRep}
    f0230.canonical[nRep,]<-w["normalised.f0199",c("b","p")]
    f0290.canonical[nRep,]<-w["normalised.f0269",c("b","p")]

    #activation of p and b for each test stimulus
    for (i in 1:numTestStim)
    {
    act.p[i,nRep]<-sum(w[testStim[i,],"p"])  
    act.b[i,nRep]<-sum(w[testStim[i,],"b"])   
    }
    
}

w.canonical = w

#limit activation to be between 0 and 1
act.p[act.p<0]<-0
act.b[act.b<0]<-0
act.p[act.p>1]<-1
act.b[act.b>1]<-1

#Calculating the mean activation of p and b across replications
#Putting it into the plot data
plot.data$mean.act.p_canonical<-apply(act.p,1,"mean")
plot.data$sd.act.p_canonical<-apply(act.p,1,"sd")
plot.data$mean.act.b_canonical<-apply(act.b,1,"mean")
plot.data$sd.act.b_canonical<-apply(act.b,1,"sd")
```


# Neutral condition
```{r message=FALSE, warning=FALSE}
neutral = tribble(
  ~VOT, ~f0,
  -20, 260,
  -10, 250,
  -10, 260,
  -10, 270,
    0, 260,
    20, 260,
    30, 250,
    30, 260,
    30, 270,
    40, 260
   )

neutral %<>% left_join(F0_reference, by='f0') %>% left_join(VOT_reference, by='VOT')

neutral %<>% 
  mutate(
    Frequency = 10,
    Outcomes = case_when(
      VOT %in% c(-20, -10, 0) ~ "b",
      TRUE ~ "p"
    ),
    Cues = paste(paste0("normalised.vot", neutral$VOT_centered), 
                 paste0("normalised.f0", neutral$F0_centered), sep = "_")
    ) %>% 
  select(Cues, Outcomes, Frequency)

neutral <- neutral %>%
  slice(rep(1:n(), each = Frequency)) %>% 
  select(-Frequency)

train = neutral
train$Cues<-as.character(train$Cues)
train$Outcomes<-as.character(train$Outcomes)
f0230.neutral.independent<-mat.or.vec(maxRep,2)
f0290.neutral.independent<-mat.or.vec(maxRep,2)
f0230.neutral.sequential<-mat.or.vec(maxRep,2)
f0290.neutral.sequential<-mat.or.vec(maxRep,2)

for (nRep in 1:maxRep)
{
    
    train<-train[sample(nrow(train)),]
    if (nRep==1) {w<-Rescorla(train, rate=0.1, w=w.canonical)}
    else {w<-(w*(nRep-1)+Rescorla(train,rate=0.1,w=w.canonical))/nRep}
    f0230.neutral.sequential[nRep,]<-w["normalised.f0199",c("b","p")]
    f0290.neutral.sequential[nRep,]<-w["normalised.f0269",c("b","p")]

    #activatons of p and b for each test stimulus
    for (i in 1:numTestStim)
    {
    act.p[i,nRep]<-sum(w[testStim[i,],"p"])  
    act.b[i,nRep]<-sum(w[testStim[i,],"b"])   
    }
    
}

w.neutral = w

#limit activations to be between 0 and 1
act.p[act.p<0]<-0
act.b[act.b<0]<-0
act.p[act.p>1]<-1
act.b[act.b>1]<-1

#Calculating the mean activation of p and b across replications
#Putting it into the plot data
plot.data$mean.act.p_neutral_sequential<-apply(act.p,1,"mean")
plot.data$sd.act.p_neutral_sequential<-apply(act.p,1,"sd")
plot.data$mean.act.b_neutral_sequential<-apply(act.b,1,"mean")
plot.data$sd.act.b_neutral_sequential<-apply(act.b,1,"sd")


# independent models
for (nRep in 1:maxRep)
{
    
    train<-train[sample(nrow(train)),]
    if (nRep==1) {w<-Rescorla(train, rate=0.1, w=w.pre)}
    else {w<-(w*(nRep-1)+Rescorla(train,rate=0.1,w=w.pre))/nRep}
    f0230.neutral.independent[nRep,]<-w["normalised.f0199",c("b","p")]
    f0290.neutral.independent[nRep,]<-w["normalised.f0269",c("b","p")]

    #activatons of p and b for each test stimulus
    for (i in 1:numTestStim)
    {
    act.p[i,nRep]<-sum(w[testStim[i,],"p"])  
    act.b[i,nRep]<-sum(w[testStim[i,],"b"])   
    }
    
}

#limit activations to be between 0 and 1
act.p[act.p<0]<-0
act.b[act.b<0]<-0
act.p[act.p>1]<-1
act.b[act.b>1]<-1

#Calculating the mean activation of p and b across replications
#Putting it into the plot data
plot.data$mean.act.p_neutral_independent<-apply(act.p,1,"mean")
plot.data$sd.act.p_neutral_independent<-apply(act.p,1,"sd")
plot.data$mean.act.b_neutral_independent<-apply(act.b,1,"mean")
plot.data$sd.act.b_neutral_independent<-apply(act.b,1,"sd")


```


# Reversed condition
```{r message=FALSE, warning=FALSE}
reversed = tribble(
  ~VOT, ~f0,
  -20, 290,
  -10, 280,
  -10, 290,
  -10, 300,
    0, 290,
    20, 230,
    30, 220,
    30, 230,
    30, 240,
    40, 230
   )

reversed %<>% left_join(F0_reference, by='f0') %>% left_join(VOT_reference, by='VOT')

reversed <- reversed %>% 
  mutate(
    Frequency = 10,
    Outcomes = case_when(
      VOT %in% c(-20, -10, 0) ~ "b",
      TRUE ~ "p"
    ),
    Cues = paste(paste0("normalised.vot", reversed$VOT_centered), 
                 paste0("normalised.f0", reversed$F0_centered), sep = "_")
  ) %>% 
  select(Cues, Outcomes, Frequency)

reversed <- reversed %>%
  slice(rep(1:n(), each = Frequency)) %>% 
  select(-Frequency) 
  

train = reversed
train$Cues<-as.character(train$Cues)
train$Outcomes<-as.character(train$Outcomes)
f0230.reversed.sequential<-mat.or.vec(maxRep,2)
f0290.reversed.sequential<-mat.or.vec(maxRep,2)
f0230.reversed.independent<-mat.or.vec(maxRep,2)
f0290.reversed.independent<-mat.or.vec(maxRep,2)


for (nRep in 1:maxRep)
{
    
    train<-train[sample(nrow(train)),]
    if (nRep==1) {w<-Rescorla(train, rate=0.1, w=w.neutral)}
    else {w<-(w*(nRep-1)+Rescorla(train, rate=0.1, w=w.neutral))/nRep}
    f0230.reversed.sequential[nRep,]<-w["normalised.f0199",c("b","p")]
    f0290.reversed.sequential[nRep,]<-w["normalised.f0269",c("b","p")]

    #activatons of p and b for each test stimulus
    for (i in 1:numTestStim)
    {
    act.p[i,nRep]<-sum(w[testStim[i,],"p"])  
    act.b[i,nRep]<-sum(w[testStim[i,],"b"])   
    }
    
}

w.reversed = w

#limit activations to be between 0 and 1
act.p[act.p<0]<-0
act.b[act.b<0]<-0
act.p[act.p>1]<-1
act.b[act.b>1]<-1

#Calculating the mean activation of p and b across replications
#Putting it into the plot data
plot.data$mean.act.p_reversed_sequential<-apply(act.p,1,"mean")
plot.data$sd.act.p_reversed_sequential<-apply(act.p,1,"sd")
plot.data$mean.act.b_reversed_sequential<-apply(act.b,1,"mean")
plot.data$sd.act.b_reversed_sequential<-apply(act.b,1,"sd")


# independent models
for (nRep in 1:maxRep)
{
    
    train<-train[sample(nrow(train)),]
    if (nRep==1) {w<-Rescorla(train, rate=0.1, w=w.pre)}
    else {w<-(w*(nRep-1)+Rescorla(train, rate=0.1, w=w.pre))/nRep}
    f0290.reversed.independent[nRep,]<-w["normalised.f0199",c("b","p")]
    f0290.reversed.independent[nRep,]<-w["normalised.f0269",c("b","p")]

    #activatons of p and b for each test stimulus
    for (i in 1:numTestStim)
    {
    act.p[i,nRep]<-sum(w[testStim[i,],"p"])  
    act.b[i,nRep]<-sum(w[testStim[i,],"b"])   
    }
    
}

#limit activations to be between 0 and 1
act.p[act.p<0]<-0
act.b[act.b<0]<-0
act.p[act.p>1]<-1
act.b[act.b>1]<-1

#Calculating the mean activation of p and b across replications
#Putting it into the plot data
plot.data$mean.act.p_reversed_independent<-apply(act.p,1,"mean")
plot.data$sd.act.p_reversed_independent<-apply(act.p,1,"sd")
plot.data$mean.act.b_reversed_independent<-apply(act.b,1,"mean")
plot.data$sd.act.b_reversed_independent<-apply(act.b,1,"sd")

```


# Plot for both independent and sequential models
```{r}
plot.data$prob.canonical<-plot.data$mean.act.p_canonical/(plot.data$mean.act.p_canonical+plot.data$mean.act.b_canonical)

plot.data$prob.reversed.independent<-plot.data$mean.act.p_reversed_independent/(plot.data$mean.act.p_reversed_independent+plot.data$mean.act.b_reversed_independent)

plot.data$prob.reversed.sequential<-plot.data$mean.act.p_reversed_sequential/(plot.data$mean.act.p_reversed_sequential+plot.data$mean.act.b_reversed_sequential)


plot.data$prob.neutral.independent<-plot.data$mean.act.p_neutral_independent/(plot.data$mean.act.p_neutral_independent+plot.data$mean.act.b_neutral_independent)
plot.data$prob.neutral.sequential<-plot.data$mean.act.p_neutral_sequential/(plot.data$mean.act.p_neutral_sequential+plot.data$mean.act.b_neutral_sequential)

ggfodata <- plot.data %>%
  group_by(F0) %>%
  summarise_at(grep("prob", names(plot.data), value = TRUE), mean) %>%
  gather(value = "meanfo", key = "condition", -F0) %>%
  mutate(Levels = ifelse(F0 == "normalised.f0199", "Low F0", "High F0"),
         condition = gsub("prob\\.", "", condition))

ggf0.independent <- ggfodata %>% 
  filter(condition =="canonical" | grepl("\\.independent", condition)) %>% 
  mutate(condition = gsub("\\.independent", "", condition),
         model = "independent")

ggf0.sequential <- ggfodata %>% 
  filter(condition =="canonical" | grepl("\\.sequential", condition)) %>% 
  mutate(condition = gsub("\\.sequential", "", condition),
         model = "sequential")
  
ggf0 <- rbind(ggf0.independent, ggf0.sequential)

gf0 <- ggf0 %>%
  ggplot(aes(x = condition, y = meanfo, group = Levels, color = Levels)) + 
  geom_point(aes(shape = Levels), size = 3) +
  scale_color_manual(values = c("Low F0" = "red", "High F0" = "blue")) +
  facet_grid(~ model) +
  theme(legend.text = element_text (size = 12),
        legend.title = element_text(size = 12, face = "bold"),
        plot.title = element_text(size = 12),
        axis.text.y = element_text(size = 10),
        axis.text.x = element_text(size = 12),
        axis.title = element_text(size = 12, face = "bold"))+
  xlab ("Condition") + ylab("Probability of /p/ responses") +
  coord_cartesian(ylim = c(0,1))


gf0


```


